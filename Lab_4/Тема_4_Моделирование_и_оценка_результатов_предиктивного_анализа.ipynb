{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='Teal'> **ТЕМА 4. МОДЕЛИРОВАНИЕ И ОЦЕНКА РЕЗУЛЬТАТОВ ПРЕДИКТИВНОГО АНАЛИЗА**"
      ],
      "metadata": {
        "id": "A_DXSt08Z9wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для выполнения задания используйте материалы лабораторной работы 4 «Предсказание эмоций по тембру голоса в реальном времени» (стр. 75-95) и лабораторной работы 5 «Предсказание эмоций по видео изображению в реальном времени» (стр. 96-119) из учебного пособия."
      ],
      "metadata": {
        "id": "yOVGFQUlZFnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<font color='Teal'> **ЗАДАНИЕ**"
      ],
      "metadata": {
        "id": "2rTfJKHzarnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Цель работы:**  \n",
        "Разработать и внедрить два отдельных алгоритма для диагностики эмоций в реальном времени: один для анализа аудиоданных, а другой для анализа видеоданных. Алгоритмы должны уметь распознавать эмоции по тембру голоса и по видеоизображению лица соответственно."
      ],
      "metadata": {
        "id": "i0K-IBjkcMyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v4yFBLxZcm-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задачи:**\n",
        "\n",
        "1. **Сбор и подготовка данных:**\n",
        "   - Изучить и загрузить наборы данных, отражающие эмоции по голосу (например, TESS и SAVEE) и по видео (например, FER2013 или другой подходящий набор данных).\n",
        "   - Преобразовать аудиофайлы в мел-кепстральные коэффициенты (MFCC) для последующего анализа.\n",
        "   - Обработать видеоданные, выделив ключевые признаки (например, с использованием метода гистограммы ориентированных градиентов (HOG) или другого подходящего метода).\n",
        "\n",
        "2. **Разработка и обучение моделей для аудиоданных:**\n",
        "   - Обучить модель для предсказания эмоций по тембру голоса, используя алгоритмы машинного обучения (например, SVM, Random Forest) или нейронные сети (например, LSTM).\n",
        "   - Провести сравнение результатов моделей и выбрать наиболее подходящую.\n",
        "\n",
        "3. **Разработка и обучение моделей для видеоданных:**\n",
        "   - Обучить модель для предсказания эмоций по видеоизображению лица, используя сверточные нейронные сети (CNN).\n",
        "   - Провести сравнение результатов моделей и выбрать наиболее подходящую.\n",
        "\n",
        "4. **Оценка и тестирование:**\n",
        "   - Провести тестирование каждой модели на различных наборах данных для оценки точности и производительности.\n",
        "   - Разработать два отдельных пользовательских интерфейса (веб-сервис или мобильное приложение), отображающих результаты предсказания эмоций в реальном времени для аудио и видео."
      ],
      "metadata": {
        "id": "By6k_qulcP7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4BVnnejRcptB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Порядок выполнения:**\n",
        "\n",
        "1. **Сбор данных (1 балл):**\n",
        "   - Загрузите наборы данных TESS и SAVEE для анализа эмоций по голосу.\n",
        "   - Загрузите набор данных FER2013 для анализа эмоций по видео.\n",
        "\n",
        "2. **Преобразование данных (2 балла):**\n",
        "   - Преобразуйте аудиофайлы в мел-кепстральные коэффициенты (MFCC) с использованием библиотеки librosa.\n",
        "   - Обработайте видеоданные, выделив ключевые признаки, например, с использованием OpenCV и dlib.\n",
        "\n",
        "3. **Разработка моделей для аудиоданных (2 балла):**\n",
        "   - Разработайте и обучите модель для предсказания эмоций по голосу с использованием SVM или LSTM.\n",
        "   - Проведите оценку точности модели.\n",
        "\n",
        "4. **Разработка моделей для видеоданных (2 балла):**\n",
        "   - Разработайте и обучите модель для предсказания эмоций по видео с использованием CNN.\n",
        "   - Проведите оценку точности модели.\n",
        "\n",
        "5. **Оценка и тестирование (2 балла):**\n",
        "   - Проведите тестирование каждой модели на различных наборах данных.\n",
        "   - Разработайте отдельные пользовательские интерфейсы (веб-сервис или мобильное приложение) для демонстрации работы каждой модели.\n",
        "\n",
        "6. **Оформление отчета (1 балл):**\n",
        "   - Подготовьте отчет, включающий все этапы работы, результаты, обсуждение и заключение.\n",
        "   - Отчет должен быть оформлен в Jupyter Notebook (Google Colab)."
      ],
      "metadata": {
        "id": "47zpxqfEdNSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "f7EXlHyUdnbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Требования к отчету:**\n",
        "\n",
        "1. **Введение:**\n",
        "   - Описать актуальность задачи предсказания эмоций по голосу и видео.\n",
        "   - Определить цели и задачи работы.\n",
        "\n",
        "2. **Методы и технологии:**\n",
        "   - Описать использованные наборы данных и методы их предобработки.\n",
        "   - Подробно описать алгоритмы и модели, примененные для анализа аудио и видео данных.\n",
        "   - Объяснить выбор архитектур нейронных сетей и методов машинного обучения.\n",
        "\n",
        "3. **Результаты:**\n",
        "   - Представить результаты обучения и тестирования моделей для аудиоданных и видеоданных отдельно.\n",
        "   - Включить метрики оценки (точность, полнота, F1-score) для каждой модели.\n",
        "   - Визуализировать результаты работы моделей, используя графики и таблицы.\n",
        "\n",
        "4. **Обсуждение:**\n",
        "   - Проанализировать результаты, выявить сильные и слабые стороны предложенного подхода.\n",
        "   - Обсудить возможные улучшения и направления для дальнейших исследований.\n",
        "\n",
        "5. **Заключение:**\n",
        "   - Подвести итоги проделанной работы, подтвердить достижение целей и задач.\n",
        "   - Описать практическую значимость и потенциальные применения разработанных алгоритмов."
      ],
      "metadata": {
        "id": "OnMmpBC3ceF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Формат отчета:**\n",
        "- Отчет должен быть оформлен в Jupyter Notebook (Google Colab).\n",
        "- Все результаты должны быть воспроизводимы, код должен быть хорошо документирован.\n",
        "- Визуализация данных и результатов должна быть выполнена с использованием библиотек Matplotlib или Seaborn."
      ],
      "metadata": {
        "id": "2mFgZWMOdrdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Демонстрация:**\n",
        "- Разработанные приложения должны быть продемонстрированы преподавателю в реальном времени.\n",
        "- Архив с кодом или ссылка на репозиторий GitHub должны быть отправлены на почту преподавателя."
      ],
      "metadata": {
        "id": "G5xG92aOasz_"
      }
    }
  ]
}